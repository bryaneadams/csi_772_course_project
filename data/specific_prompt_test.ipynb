{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import google.generativeai as palm\n",
    "from utils import VectorEmbeddings, remove_html_tags, remove_req_qual_str, job_categories_to_string\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time, json, re, ast\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    filename=\"script.log\",\n",
    "    format=\"%(asctime)s %(message)s\",\n",
    "    filemode=\"w\",\n",
    "    level=logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def job_categories_to_string(value: str) -> str:\n",
    "    \"\"\"Transforms the job categories to just the actual occupational series\n",
    "\n",
    "    Args:\n",
    "        value (str): The value from the 'job_categories'\n",
    "\n",
    "    Returns:\n",
    "        str: string that it returns with the OSCs in one comma separated string\n",
    "\n",
    "    Examples:\n",
    "        >>> job_categories_to_string(\"[{'series': '0808'}, {'series': '0810'}]\")\n",
    "        '0808, 0810'\n",
    "    \"\"\"\n",
    "    series_list = ast.literal_eval(value)\n",
    "    series_values = [item[\"series\"] for item in series_list]\n",
    "    try:\n",
    "        return \", \".join(series_values)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_raw_data_to_dict(\n",
    "    path: str = \"../../raw_data\",\n",
    "    files: list = None,\n",
    "    build_teams: bool = False,\n",
    "    build_terminal_teams: bool = True,\n",
    ") -> Tuple[dict, list]:\n",
    "    \"\"\"Reads in raw data and returns a dict of dataframes and a list of  months.\n",
    "\n",
    "    Args:\n",
    "        path (str, optional): Path to the raw data directory. Defaults to \"../../raw_data\".\n",
    "        files (list, optional): A list of files you want to read in. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[dict, list]:  dict of data frames, the key is the month, and the value is the dataframe and a list of months sorted\n",
    "    \"\"\"\n",
    "\n",
    "    if not files:\n",
    "        p = Path(path)\n",
    "        files = [str(file) for file in p.glob(\"[0-9]*txt\")]\n",
    "        files.sort()\n",
    "\n",
    "    df_dict = {}\n",
    "    team_dicts_by_month = {}\n",
    "    month_keys = []\n",
    "\n",
    "    for file in files:\n",
    "        df = pd.read_table(file, sep=\"|\", encoding=\"windows-1252\", low_memory=False)\n",
    "        month = str(file).rsplit(\"/\", 1)[1].replace(\".txt\", \"\")\n",
    "\n",
    "        if build_teams:\n",
    "            if build_terminal_teams:\n",
    "                team_dicts_by_month[month] = build_team_dict(df)\n",
    "            else:\n",
    "                team_dicts_by_month[month] = build_team_dict_with_non_terminal(df)\n",
    "        df[\"month\"] = month\n",
    "        month_keys.append(month)\n",
    "\n",
    "        df_dict[month] = df\n",
    "\n",
    "    month_keys.sort()\n",
    "\n",
    "    if build_teams:\n",
    "        return df_dict, month_keys, team_dicts_by_month\n",
    "    else:\n",
    "        return df_dict, month_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/bryanadams/github/LaborFlows/usa_jobs/raw_data'\n",
    "p = Path(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [str(file) for file in p.glob(\"[0-9]*txt\")]\n",
    "year_pattern = re.compile(r'(2017|2018|2019|2020)')\n",
    "matching_files = []\n",
    "for file in files:\n",
    "    if re.search(year_pattern, file):\n",
    "        matching_files.append(file)\n",
    "\n",
    "matching_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict, month_keys = read_raw_data_to_dict(files = matching_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "osc_count_dict = {}\n",
    "for people in df_dict.values():\n",
    "    unique_values, unique_counts = np.unique(people['SERIES'].to_list(), return_counts=True)\n",
    "    for z in zip(unique_values, unique_counts):\n",
    "        osc = str(z[0])\n",
    "        osc = osc.replace('.0','')\n",
    "        if len(osc) == 2:\n",
    "            osc = '00'+osc\n",
    "        if len(osc) == 3:\n",
    "            osc = '0'+osc\n",
    "        if osc not in osc_count_dict.keys():\n",
    "            osc_count_dict[osc] = z[1]\n",
    "        else:\n",
    "            osc_count_dict[osc] += z[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_dict = dict(sorted(osc_count_dict.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['1102', '0346', '0801', '0810', '0830', '0301', '0855', '2210', '0340', '0343', '0854', '1670', '1550', '1515', '1910', '0850', '1101', '0861', '2010', '0560', '1301', '1105', '2003', '0401', '0893', '1170', '1712', '1083', '0808', '0501', '2001', '1320', '0802', '0819', '1310', '0896', '1350', '0809', '0803', '0601', '0806', '0391', '0510', '1150', '2130', '0180', '1103', '1520', '1601', '2032', '0403', '0020', '1008', '0413', '1382', '0028', '1640', '1384', '0858', '1152', '0193', '2181', '1529', '0505', '1373', '1171', '0804', '0807', '0062', '1306', '0018', '1176', '1313', '1340', '1370', '0905', '0856', '0405', '1315', '0486', '0602', '1321', '2101', '0408', '1371', '1316', '0630', '0871', '0415', '0511', '0690', '0899', '0610', '0414', '0404', '0150', '1374', '0132', '1360', '0080', '0460', '0817', '1311', '1530', '0482', '0840', '1399', '0089', '1130', '0nan', '0110', '0101', '2150', '1501', '2030', '2005', '0170', '0561', '0308', '0181', '0201', '0341', '1801', '51C0', '51Z1', '0303', '0344'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_15_osc = ['1102', '0346', '0801', '0810', '0830', '0301', '0855', '2210', '0340', '0343', '0854', '1670', '1550', '1515', '1910']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_df = pd.read_excel('../onet_competencies/knowledge_competencies.xlsx', skiprows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../.api_key', 'r') as file:\n",
    "    api_key = file.readline()\n",
    "vector_embeddings = VectorEmbeddings(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df = pd.read_json('job_descriptions.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df['osc'] = job_df['job_categories'].apply(job_categories_to_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_ids = []\n",
    "for i, row in job_df.iterrows():\n",
    "    if row['osc']:\n",
    "        if ',' not in row['osc']:\n",
    "            if row['osc'] in top_15_osc:\n",
    "                job_ids.append(row['usajobs_control_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46804"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_models = [m for m in palm.list_models() if 'generateText' in m.supported_generation_methods]\n",
    "text_model = text_models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example high level requirement for this knowledge is {} while an example low level requirement for this knowledge is {}.\n",
    "\n",
    "def make_ksa_prompt(k_skill, k_description, job_ad):\n",
    "    query = 'Does this job ad require {} knowledge to perform the job?'.format(k_skill)\n",
    "    leading_text = '{} is the {}. Look at the job ad and decide if {} is required to perform this job. If {} is required please provide the specific tasks in a bulletized format from the job ad that relate to {}, if not simply say no'.format(k_skill, k_description,k_skill, k_skill, k_skill)\n",
    "    prompt = vector_embeddings.make_prompt(leading_text, query, job_ad)\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answers(prompt, text_model, candidate_count: int = 3, temperature:float = 0.5):\n",
    "    count = 0\n",
    "    while count<4:\n",
    "        try:\n",
    "            answers = palm.generate_text(prompt=prompt,\n",
    "                                    model=text_model,\n",
    "                                    candidate_count=candidate_count,\n",
    "                                    temperature=temperature,\n",
    "                                    max_output_tokens=1000)\n",
    "            count = 10\n",
    "        except:\n",
    "            answers = 'FAILED'\n",
    "            logging.info(\"FAILED\")\n",
    "            count += 1\n",
    "            time.sleep((count+1)**2*6)\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ksa_answers(ksa,prompt,**kwargs):\n",
    "    return_dict = {ksa:generate_answers(prompt,**kwargs)}\n",
    "    return return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_if_ksa_is_present(answers):\n",
    "    for answer in answers.candidates:\n",
    "        if answer['output'].lower().startswith('no'):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a dict of the prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_df = job_df[job_df['usajobs_control_number'].isin(job_ids[51:1000])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_prompts = {}\n",
    "for job_index, job_row in run_df.iterrows():\n",
    "    job_prompts[job_row['usajobs_control_number']] = {}\n",
    "    job = remove_req_qual_str(remove_html_tags(job_row['requirements_qualifications']))\n",
    "    for ksa_index, ksa_row in knowledge_df.iterrows():\n",
    "        job_prompts[job_row['usajobs_control_number']][ksa_row['Element Name']] = make_ksa_prompt(ksa_row['Element Name'].lower(), ksa_row['Element Description'].lower(), job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id_ksa_dict = {}\n",
    "for job_id , ksa_prompts in job_prompts.items():\n",
    "    job_responses = []\n",
    "    response_list = []\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        for ksa, prompt in ksa_prompts.items():\n",
    "            job_responses.append(executor.submit(ksa_answers, ksa=ksa, \n",
    "                                                prompt = prompt, \n",
    "                                                text_model = text_model,\n",
    "                                                temperature = 0))\n",
    "    for body in as_completed(job_responses):\n",
    "        response_list.append(body.result())\n",
    "\n",
    "    ksa_list = []\n",
    "    for response in response_list:\n",
    "        for ksa, answer in response.items():\n",
    "            if answer == 'FAILED':\n",
    "                ksa_list.append(ksa+'FAILED')\n",
    "            elif determine_if_ksa_is_present(answer):\n",
    "                ksa_list.append(ksa)\n",
    "\n",
    "    job_id_ksa_dict[job_id] = ksa_list\n",
    "    logging.info(\"Finished: {}\".format(job_id))\n",
    "    time.sleep(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ksa_run_three.json', 'w') as json_file:\n",
    "    json.dump(job_id_ksa_dict, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksa_list = []\n",
    "for response in response_list:\n",
    "    for ksa, answer in response.items():\n",
    "        if determine_if_ksa_is_present(answer):\n",
    "            ksa_list.append(ksa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['English Language',\n",
       " 'Law and Government',\n",
       " 'Economics and Accounting',\n",
       " 'Education and Training',\n",
       " 'Business and Management',\n",
       " 'Administration and Management']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ksa_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    for i, row in job_df.head(n=2).iterrows():\n",
    "        print(row['usajobs_control_number'])       \n",
    "        job_responses.append(executor.submit(determine_ksa_vector, job_id = row['usajobs_control_number'], job = row['requirements_qualifications'], ksa_df = knowledge_df, text_model=text_model))\n",
    "    for body in as_completed(job_responses):\n",
    "        response_list.append(body.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([514962300, 514177900, 540927700, 534312000, 546156800])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_prompts.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_ksa_vector(job_id, job, ksa_df, text_model, **kwargs):\n",
    "    ksa = []\n",
    "    non_ksa = []\n",
    "    return_dict = {}\n",
    "    # for i, row in knowledge_df.iterrows():\n",
    "    for i, row in ksa_df.iterrows():\n",
    "        prompt = make_ksa_prompt(row['Element Name'].lower(), row['Element Description'].lower(), job)\n",
    "\n",
    "        answers = generate_answers(prompt, text_model, **kwargs)\n",
    "\n",
    "        add = determine_if_ksa_is_present(answers)\n",
    "\n",
    "        if add:\n",
    "            ksa.append(row['Element Name'])\n",
    "        else:\n",
    "            non_ksa.append(row['Element Name'])\n",
    "\n",
    "    return_dict[job_id] = {'ksa': ksa, 'non_ksa': non_ksa}\n",
    "    \n",
    "    return return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# job_responses = [] \n",
    "# response_list = []\n",
    "# with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "#     for file in test_list:\n",
    "#         print('yes')       \n",
    "#         job_responses.append(executor.submit(determine_ksa_vector, file, ksa_df = knowledge_df, text_model=text_model))\n",
    "#     for body in as_completed(job_responses):\n",
    "#         response_list.append(body.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514962300\n",
      "514177900\n"
     ]
    }
   ],
   "source": [
    "job_responses = [] \n",
    "response_list = []\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    for i, row in job_df.head(n=2).iterrows():\n",
    "        print(row['usajobs_control_number'])       \n",
    "        job_responses.append(executor.submit(determine_ksa_vector, job_id = row['usajobs_control_number'], job = row['requirements_qualifications'], ksa_df = knowledge_df, text_model=text_model))\n",
    "    for body in as_completed(job_responses):\n",
    "        response_list.append(body.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Administration and Management',\n",
       "  'Engineering and Technology',\n",
       "  'Engineering and Technology',\n",
       "  'Mathematics and Science',\n",
       "  'Mathematics',\n",
       "  'Education and Training'],\n",
       " ['Business and Management',\n",
       "  'Administrative',\n",
       "  'Economics and Accounting',\n",
       "  'Sales and Marketing',\n",
       "  'Customer and Personal Service',\n",
       "  'Personnel and Human Resources',\n",
       "  'Manufacturing and Production',\n",
       "  'Production and Processing',\n",
       "  'Food Production',\n",
       "  'Computers and Electronics',\n",
       "  'Design',\n",
       "  'Building and Construction',\n",
       "  'Mechanical',\n",
       "  'Physics',\n",
       "  'Chemistry',\n",
       "  'Biology',\n",
       "  'Psychology',\n",
       "  'Sociology and Anthropology',\n",
       "  'Geography',\n",
       "  'Health Services',\n",
       "  'Medicine and Dentistry',\n",
       "  'Therapy and Counseling',\n",
       "  'Arts and Humanities',\n",
       "  'English Language',\n",
       "  'Foreign Language',\n",
       "  'Fine Arts',\n",
       "  'History and Archeology',\n",
       "  'Philosophy and Theology',\n",
       "  'Law and Public Safety',\n",
       "  'Public Safety and Security',\n",
       "  'Law and Government',\n",
       "  'Communications',\n",
       "  'Telecommunications',\n",
       "  'Communications and Media',\n",
       "  'Transportation'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "determine_ksa_vector(job, knowledge_df, text_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Engineering and Technology',\n",
       "  'Engineering and Technology',\n",
       "  'Mathematics and Science',\n",
       "  'Mathematics',\n",
       "  'Education and Training',\n",
       "  'Public Safety and Security'],\n",
       " ['Business and Management',\n",
       "  'Administration and Management',\n",
       "  'Administrative',\n",
       "  'Economics and Accounting',\n",
       "  'Sales and Marketing',\n",
       "  'Customer and Personal Service',\n",
       "  'Personnel and Human Resources',\n",
       "  'Manufacturing and Production',\n",
       "  'Production and Processing',\n",
       "  'Food Production',\n",
       "  'Computers and Electronics',\n",
       "  'Design',\n",
       "  'Building and Construction',\n",
       "  'Mechanical',\n",
       "  'Physics',\n",
       "  'Chemistry',\n",
       "  'Biology',\n",
       "  'Psychology',\n",
       "  'Sociology and Anthropology',\n",
       "  'Geography',\n",
       "  'Health Services',\n",
       "  'Medicine and Dentistry',\n",
       "  'Therapy and Counseling',\n",
       "  'Arts and Humanities',\n",
       "  'English Language',\n",
       "  'Foreign Language',\n",
       "  'Fine Arts',\n",
       "  'History and Archeology',\n",
       "  'Philosophy and Theology',\n",
       "  'Law and Public Safety',\n",
       "  'Law and Government',\n",
       "  'Communications',\n",
       "  'Telecommunications',\n",
       "  'Communications and Media',\n",
       "  'Transportation'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "determine_ksa_vector(job, knowledge_df, text_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Administration and Management',\n",
       "  'Engineering and Technology',\n",
       "  'Engineering and Technology',\n",
       "  'Design',\n",
       "  'Building and Construction',\n",
       "  'Mathematics and Science',\n",
       "  'Mathematics',\n",
       "  'Physics',\n",
       "  'Geography',\n",
       "  'Medicine and Dentistry',\n",
       "  'Therapy and Counseling',\n",
       "  'Education and Training',\n",
       "  'English Language'],\n",
       " ['Business and Management',\n",
       "  'Administrative',\n",
       "  'Economics and Accounting',\n",
       "  'Sales and Marketing',\n",
       "  'Customer and Personal Service',\n",
       "  'Personnel and Human Resources',\n",
       "  'Manufacturing and Production',\n",
       "  'Production and Processing',\n",
       "  'Food Production',\n",
       "  'Computers and Electronics',\n",
       "  'Mechanical',\n",
       "  'Chemistry',\n",
       "  'Biology',\n",
       "  'Psychology',\n",
       "  'Sociology and Anthropology',\n",
       "  'Health Services',\n",
       "  'Arts and Humanities',\n",
       "  'Foreign Language',\n",
       "  'Fine Arts',\n",
       "  'History and Archeology',\n",
       "  'Philosophy and Theology',\n",
       "  'Law and Public Safety',\n",
       "  'Public Safety and Security',\n",
       "  'Law and Government',\n",
       "  'Communications',\n",
       "  'Telecommunications',\n",
       "  'Communications and Media',\n",
       "  'Transportation'])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ksa, non_ksa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Administration and Management',\n",
       "  'Engineering and Technology',\n",
       "  'Engineering and Technology',\n",
       "  'Design',\n",
       "  'Building and Construction',\n",
       "  'Mathematics and Science',\n",
       "  'Mathematics',\n",
       "  'Physics',\n",
       "  'Geography',\n",
       "  'Medicine and Dentistry',\n",
       "  'Therapy and Counseling',\n",
       "  'Education and Training',\n",
       "  'English Language'],\n",
       " ['Business and Management',\n",
       "  'Administrative',\n",
       "  'Economics and Accounting',\n",
       "  'Sales and Marketing',\n",
       "  'Customer and Personal Service',\n",
       "  'Personnel and Human Resources',\n",
       "  'Manufacturing and Production',\n",
       "  'Production and Processing',\n",
       "  'Food Production',\n",
       "  'Computers and Electronics',\n",
       "  'Mechanical',\n",
       "  'Chemistry',\n",
       "  'Biology',\n",
       "  'Psychology',\n",
       "  'Sociology and Anthropology',\n",
       "  'Health Services',\n",
       "  'Arts and Humanities',\n",
       "  'Foreign Language',\n",
       "  'Fine Arts',\n",
       "  'History and Archeology',\n",
       "  'Philosophy and Theology',\n",
       "  'Law and Public Safety',\n",
       "  'Public Safety and Security',\n",
       "  'Law and Government',\n",
       "  'Communications',\n",
       "  'Telecommunications',\n",
       "  'Communications and Media',\n",
       "  'Transportation'])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ksa, non_ksa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Administration and Management',\n",
       "  'Engineering and Technology',\n",
       "  'Engineering and Technology',\n",
       "  'Design',\n",
       "  'Building and Construction',\n",
       "  'Mathematics and Science',\n",
       "  'Mathematics',\n",
       "  'Physics',\n",
       "  'Geography',\n",
       "  'Medicine and Dentistry',\n",
       "  'Therapy and Counseling',\n",
       "  'Education and Training'],\n",
       " ['Business and Management',\n",
       "  'Administrative',\n",
       "  'Economics and Accounting',\n",
       "  'Sales and Marketing',\n",
       "  'Customer and Personal Service',\n",
       "  'Personnel and Human Resources',\n",
       "  'Manufacturing and Production',\n",
       "  'Production and Processing',\n",
       "  'Food Production',\n",
       "  'Computers and Electronics',\n",
       "  'Mechanical',\n",
       "  'Chemistry',\n",
       "  'Biology',\n",
       "  'Psychology',\n",
       "  'Sociology and Anthropology',\n",
       "  'Health Services',\n",
       "  'Arts and Humanities',\n",
       "  'English Language',\n",
       "  'Foreign Language',\n",
       "  'Fine Arts',\n",
       "  'History and Archeology',\n",
       "  'Philosophy and Theology',\n",
       "  'Law and Public Safety',\n",
       "  'Public Safety and Security',\n",
       "  'Law and Government',\n",
       "  'Communications',\n",
       "  'Telecommunications',\n",
       "  'Communications and Media',\n",
       "  'Transportation'])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ksa, non_ksa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = make_ksa_prompt(knowledge_df.iloc[3]['Element Name'].lower(), knowledge_df.iloc[3]['Element Description'].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate 0: No\n",
      "\n",
      "Candidate 1: No\n",
      "\n",
      "Candidate 2: No, transportation is not required to perform the job.\n",
      "\n",
      "Candidate 3: No\n",
      "\n",
      "Candidate 4: No\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temperature = 0.5\n",
    "answers = palm.generate_text(prompt=prompt,\n",
    "                            model=text_model,\n",
    "                            candidate_count=5,\n",
    "                            temperature=temperature,\n",
    "                            max_output_tokens=1000)\n",
    "for i, candidate in enumerate(answer.candidates):\n",
    "  print(f\"Candidate {i}: {candidate['output']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n"
     ]
    }
   ],
   "source": [
    "for answer in answers.candidates:\n",
    "    if answer['output'].lower().startswith('no'):\n",
    "        print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, candidate in enumerate(answer.candidates):\n",
    "  print(f\"Candidate {i}: {candidate['output']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Knowledge of administrative and office procedures and systems such as word processing, managing files and records, stenography and transcription, designing forms, and workplace terminology.'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knowledge_df.iloc[2]['Element Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
